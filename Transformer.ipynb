{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5240be2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_pickle(\"team_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c2fe9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_cols = [\n",
    "    'ally_ban0', 'ally_ban1', 'ally_ban2', 'ally_ban3', 'ally_ban4',\n",
    "    'enemy_ban0', 'enemy_ban1', 'enemy_ban2', 'enemy_ban3', 'enemy_ban4',\n",
    "    'ally_TOP', 'ally_JUNGLE', 'ally_MIDDLE', 'ally_BOTTOM', 'ally_UTILITY',\n",
    "    'enemy_TOP', 'enemy_JUNGLE', 'enemy_MIDDLE', 'enemy_BOTTOM', 'enemy_UTILITY',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb9f767d",
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_cols = [\n",
    "    'ally_BOTTOM', 'ally_JUNGLE', 'ally_MIDDLE', 'ally_TOP', 'ally_UTILITY',\n",
    "    'enemy_TOP', 'enemy_JUNGLE', 'enemy_MIDDLE', 'enemy_BOTTOM', 'enemy_UTILITY',\n",
    "    'ally_ban0', 'ally_ban1', 'ally_ban2', 'ally_ban3', 'ally_ban4',\n",
    "    'enemy_ban0', 'enemy_ban1', 'enemy_ban2', 'enemy_ban3', 'enemy_ban4',\n",
    "]\n",
    "\n",
    "# Build champion vocabulary\n",
    "all_champs = pd.unique(df[champ_cols].values.ravel())\n",
    "champ2id = {c: i for i, c in enumerate(all_champs)}\n",
    "id2champ = {i: c for c, i in champ2id.items()}\n",
    "\n",
    "MASK_ID = len(champ2id)\n",
    "PAD_ID  = len(champ2id) + 1\n",
    "vocab_size = len(champ2id) + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4360f5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class DraftDataset(Dataset):\n",
    "    def __init__(self, df, champ2id, slot_cols, role_slot_name='ally_TOP'):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.champ2id = champ2id\n",
    "        self.slot_cols = slot_cols\n",
    "        self.role_slot_idx = slot_cols.index(role_slot_name)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        # Sequence of champs in fixed slot order\n",
    "        champs = [row[c] for c in self.slot_cols]\n",
    "        seq = torch.tensor([self.champ2id[c] for c in champs], dtype=torch.long)\n",
    "\n",
    "        # Target is the champ in the role slot to predict\n",
    "        target = seq[self.role_slot_idx].clone()\n",
    "\n",
    "        # Mask that slot in the input\n",
    "        masked_seq = seq.clone()\n",
    "        masked_seq[self.role_slot_idx] = MASK_ID\n",
    "        slot_ids = torch.arange(len(self.slot_cols), dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": masked_seq,   # [L]\n",
    "            \"slot_ids\": slot_ids,      # [L]\n",
    "            \"target\": target,          # scalar\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49cc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DraftSlotTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_champs: int,\n",
    "        num_slots: int = 20,\n",
    "        d_model: int = 256,\n",
    "        n_heads: int = 8,\n",
    "        n_layers: int = 4,\n",
    "        dim_ff: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_champs = num_champs\n",
    "        self.num_slots = num_slots\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # Embeddings\n",
    "        self.champ_embed = nn.Embedding(num_champs, d_model)\n",
    "        self.slot_embed  = nn.Embedding(num_slots, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,   # [B, L, D]\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "        # Head to predict champ for a specific slot\n",
    "        self.head = nn.Linear(d_model, num_champs)\n",
    "\n",
    "    def forward(self, input_ids, slot_ids, target_slot_idx):\n",
    "        \"\"\"\n",
    "        input_ids:    [B, L] champ ids (with MASK_ID at target slot)\n",
    "        slot_ids:     [B, L] slot indices 0..L-1\n",
    "        target_slot_idx: int (which slot we're predicting, e.g. ally_TOP index)\n",
    "        \"\"\"\n",
    "        x = self.champ_embed(input_ids) + self.slot_embed(slot_ids)  # [B, L, D]\n",
    "        h = self.encoder(x)                                         # [B, L, D]\n",
    "\n",
    "        # Hidden rep at the target slot\n",
    "        B, L, D = h.shape\n",
    "        target_pos = torch.full((B,), target_slot_idx, dtype=torch.long, device=h.device)\n",
    "        h_target = h[torch.arange(B, device=h.device), target_pos]  # [B, D]\n",
    "\n",
    "        logits = self.head(h_target)  # [B, num_champs]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "693ff340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, batch, target_slot_idx):\n",
    "    input_ids = batch[\"input_ids\"].to(model.champ_embed.weight.device)  # [B, L]\n",
    "    slot_ids  = batch[\"slot_ids\"].to(model.champ_embed.weight.device)   # [B, L]\n",
    "    targets   = batch[\"target\"].to(model.champ_embed.weight.device)     # [B]\n",
    "\n",
    "    logits = model(input_ids, slot_ids, target_slot_idx)  # [B, V]\n",
    "    loss = F.cross_entropy(logits, targets)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3880b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Vocab size (with MASK + PAD): 173\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "\n",
    "# basic device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "df = pd.read_pickle(\"team_df.pkl\")\n",
    "\n",
    "\n",
    "champ_cols = [\n",
    "    'ally_BOTTOM', 'ally_JUNGLE', 'ally_MIDDLE', 'ally_TOP', 'ally_UTILITY',\n",
    "    'enemy_TOP', 'enemy_JUNGLE', 'enemy_MIDDLE', 'enemy_BOTTOM', 'enemy_UTILITY',\n",
    "    'ally_ban0', 'ally_ban1', 'ally_ban2', 'ally_ban3', 'ally_ban4',\n",
    "    'enemy_ban0', 'enemy_ban1', 'enemy_ban2', 'enemy_ban3', 'enemy_ban4',\n",
    "]\n",
    "\n",
    "# Get all champs, drop NaNs\n",
    "all_champs = pd.unique(df[champ_cols].values.ravel())\n",
    "all_champs = [c for c in all_champs if pd.notna(c)]\n",
    "all_champs = np.sort(all_champs)\n",
    "\n",
    "champ2id = {c: i for i, c in enumerate(all_champs)}\n",
    "id2champ = {i: c for c, i in champ2id.items()}\n",
    "\n",
    "MASK_ID = len(champ2id)       # special \"to predict\" token\n",
    "PAD_ID  = len(champ2id) + 1   # special \"empty/no champ\" token\n",
    "vocab_size = len(champ2id) + 2\n",
    "\n",
    "print(\"Vocab size (with MASK + PAD):\", vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941e36e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_cols = [\n",
    "    'ally_ban0', 'ally_ban1', 'ally_ban2', 'ally_ban3', 'ally_ban4',\n",
    "    'enemy_ban0', 'enemy_ban1', 'enemy_ban2', 'enemy_ban3', 'enemy_ban4',\n",
    "    'ally_TOP', 'ally_JUNGLE', 'ally_MIDDLE', 'ally_BOTTOM', 'ally_UTILITY',\n",
    "    'enemy_TOP', 'enemy_JUNGLE', 'enemy_MIDDLE', 'enemy_BOTTOM', 'enemy_UTILITY',\n",
    "]\n",
    "\n",
    "class DraftDataset(Dataset):\n",
    "    def __init__(self, df, champ2id, slot_cols, role_slot_name, mask_id, pad_id):\n",
    "        \"\"\"\n",
    "        role_slot_name: which slot we are predicting (e.g. 'ally_TOP')\n",
    "        We mask that slot in input and use the original champ as target.\n",
    "        \"\"\"\n",
    "        self.slot_cols = slot_cols\n",
    "        self.champ2id = champ2id\n",
    "        self.mask_id = mask_id\n",
    "        self.pad_id = pad_id\n",
    "        self.role_slot_idx = slot_cols.index(role_slot_name)\n",
    "\n",
    "        # Filter out rows where the target slot is NaN (no champ to predict)\n",
    "        df = df[df[role_slot_name].notna()].copy()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        champs = [row[c] for c in self.slot_cols]\n",
    "\n",
    "        # Map champs to IDs, using PAD_ID for NaNs\n",
    "        ids = []\n",
    "        for c in champs:\n",
    "            if pd.isna(c):\n",
    "                ids.append(self.pad_id)\n",
    "            else:\n",
    "                ids.append(self.champ2id[c])\n",
    "        seq = torch.tensor(ids, dtype=torch.long)\n",
    "\n",
    "        # Target = champ in the role slot\n",
    "        target = seq[self.role_slot_idx].clone()\n",
    "\n",
    "        # Mask that slot in the input sequence\n",
    "        masked_seq = seq.clone()\n",
    "        masked_seq[self.role_slot_idx] = self.mask_id\n",
    "\n",
    "        # slot ids\n",
    "        L = len(self.slot_cols)\n",
    "        slot_ids = torch.arange(L, dtype=torch.long)\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": masked_seq,  # [L]\n",
    "            \"slot_ids\": slot_ids,     # [L]\n",
    "            \"target\": target,         # scalar\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1322c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DraftSlotTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_champs: int,\n",
    "        num_slots: int = 20,\n",
    "        d_model: int = 256,\n",
    "        n_heads: int = 8,\n",
    "        n_layers: int = 4,\n",
    "        dim_ff: int = 512,\n",
    "        dropout: float = 0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_champs = num_champs\n",
    "        self.num_slots = num_slots\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.champ_embed = nn.Embedding(num_champs, d_model)\n",
    "        self.slot_embed  = nn.Embedding(num_slots, d_model)\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=n_heads,\n",
    "            dim_feedforward=dim_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,  # [B, L, D]\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
    "\n",
    "        self.head = nn.Linear(d_model, num_champs)\n",
    "\n",
    "    def forward(self, input_ids, slot_ids, target_slot_idx):\n",
    "        \"\"\"\n",
    "        input_ids:      [B, L] champ ids with MASK_ID at target slot\n",
    "        slot_ids:       [B, L] slot indices 0..L-1\n",
    "        target_slot_idx: int (same for the whole batch)\n",
    "        \"\"\"\n",
    "        x = self.champ_embed(input_ids) + self.slot_embed(slot_ids)  # [B, L, D]\n",
    "        h = self.encoder(x)                                          # [B, L, D]\n",
    "\n",
    "        B, L, D = h.shape\n",
    "        target_pos = torch.full((B,), target_slot_idx, dtype=torch.long, device=h.device)\n",
    "        h_target = h[torch.arange(B, device=h.device), target_pos]   # [B, D]\n",
    "\n",
    "        logits = self.head(h_target)  # [B, num_champs]\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8079f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, target_slot_idx):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        input_ids = batch[\"input_ids\"].to(device)  # [B, L]\n",
    "        slot_ids  = batch[\"slot_ids\"].to(device)   # [B, L]\n",
    "        targets   = batch[\"target\"].to(device)     # [B]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, slot_ids, target_slot_idx)  # [B, V]\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batch_size = targets.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "    return total_loss / total_samples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, target_slot_idx, topk_list=(1, 3, 5)):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "\n",
    "    # counts for each k\n",
    "    correct_at_k = {k: 0 for k in topk_list}\n",
    "\n",
    "    for batch in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        input_ids = batch[\"input_ids\"].to(device)  # [B, L]\n",
    "        slot_ids  = batch[\"slot_ids\"].to(device)   # [B, L]\n",
    "        targets   = batch[\"target\"].to(device)     # [B]\n",
    "\n",
    "        logits = model(input_ids, slot_ids, target_slot_idx)  # [B, V]\n",
    "        loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        batch_size = targets.size(0)\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "        probs = F.softmax(logits, dim=-1)  # [B, V]\n",
    "\n",
    "        for k in topk_list:\n",
    "            topk = torch.topk(probs, k=k, dim=-1).indices  # [B, k]\n",
    "            # check if target in top-k\n",
    "            match = (topk == targets.unsqueeze(-1)).any(dim=-1)  # [B]\n",
    "            correct_at_k[k] += match.sum().item()\n",
    "\n",
    "    avg_loss = total_loss / total_samples\n",
    "    metrics = {\"loss\": avg_loss}\n",
    "    for k in topk_list:\n",
    "        metrics[f\"top{k}_acc\"] = correct_at_k[k] / total_samples\n",
    "\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b422214b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training model for role: ally_TOP ===\n",
      "\n",
      "Role ally_TOP - Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0545\n",
      "Val loss: 3.9454 | top1: 0.0886 | top3: 0.1979 | top5: 0.2793\n",
      "\n",
      "Role ally_TOP - Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.9091\n",
      "Val loss: 3.9027 | top1: 0.0948 | top3: 0.2093 | top5: 0.2925\n",
      "\n",
      "Role ally_TOP - Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.8488\n",
      "Val loss: 3.8835 | top1: 0.0946 | top3: 0.2096 | top5: 0.2949\n",
      "\n",
      "Role ally_TOP - Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.8005\n",
      "Val loss: 3.8819 | top1: 0.0946 | top3: 0.2122 | top5: 0.2964\n",
      "\n",
      "Role ally_TOP - Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.7490\n",
      "Val loss: 3.8906 | top1: 0.0935 | top3: 0.2119 | top5: 0.2981\n",
      "\n",
      "Role ally_TOP - Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.6969\n",
      "Val loss: 3.9115 | top1: 0.0930 | top3: 0.2052 | top5: 0.2909\n",
      "\n",
      "Role ally_TOP - Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.6418\n",
      "Val loss: 3.9390 | top1: 0.0883 | top3: 0.2009 | top5: 0.2866\n",
      "\n",
      "Role ally_TOP - Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5832\n",
      "Val loss: 3.9694 | top1: 0.0874 | top3: 0.1976 | top5: 0.2802\n",
      "\n",
      "Role ally_TOP - Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5209\n",
      "Val loss: 3.9987 | top1: 0.0855 | top3: 0.1954 | top5: 0.2794\n",
      "\n",
      "Role ally_TOP - Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4619\n",
      "Val loss: 4.0367 | top1: 0.0849 | top3: 0.1914 | top5: 0.2743\n",
      "\n",
      "=== Training model for role: ally_JUNGLE ===\n",
      "\n",
      "Role ally_JUNGLE - Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.8842\n",
      "Val loss: 3.7806 | top1: 0.0774 | top3: 0.1933 | top5: 0.2816\n",
      "\n",
      "Role ally_JUNGLE - Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.7617\n",
      "Val loss: 3.7490 | top1: 0.0762 | top3: 0.1973 | top5: 0.2896\n",
      "\n",
      "Role ally_JUNGLE - Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.7088\n",
      "Val loss: 3.7454 | top1: 0.0821 | top3: 0.1993 | top5: 0.2904\n",
      "\n",
      "Role ally_JUNGLE - Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.6650\n",
      "Val loss: 3.7476 | top1: 0.0776 | top3: 0.1969 | top5: 0.2899\n",
      "\n",
      "Role ally_JUNGLE - Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.6193\n",
      "Val loss: 3.7555 | top1: 0.0775 | top3: 0.1922 | top5: 0.2858\n",
      "\n",
      "Role ally_JUNGLE - Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5698\n",
      "Val loss: 3.7796 | top1: 0.0749 | top3: 0.1904 | top5: 0.2818\n",
      "\n",
      "Role ally_JUNGLE - Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5164\n",
      "Val loss: 3.8083 | top1: 0.0772 | top3: 0.1932 | top5: 0.2823\n",
      "\n",
      "Role ally_JUNGLE - Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4587\n",
      "Val loss: 3.8312 | top1: 0.0736 | top3: 0.1846 | top5: 0.2703\n",
      "\n",
      "Role ally_JUNGLE - Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.3999\n",
      "Val loss: 3.8673 | top1: 0.0698 | top3: 0.1769 | top5: 0.2671\n",
      "\n",
      "Role ally_JUNGLE - Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.3431\n",
      "Val loss: 3.9031 | top1: 0.0696 | top3: 0.1768 | top5: 0.2617\n",
      "\n",
      "=== Training model for role: ally_MIDDLE ===\n",
      "\n",
      "Role ally_MIDDLE - Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0827\n",
      "Val loss: 3.9624 | top1: 0.0781 | top3: 0.1823 | top5: 0.2633\n",
      "\n",
      "Role ally_MIDDLE - Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.9288\n",
      "Val loss: 3.9337 | top1: 0.0817 | top3: 0.1865 | top5: 0.2691\n",
      "\n",
      "Role ally_MIDDLE - Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.8717\n",
      "Val loss: 3.9163 | top1: 0.0850 | top3: 0.1947 | top5: 0.2781\n",
      "\n",
      "Role ally_MIDDLE - Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.8250\n",
      "Val loss: 3.9156 | top1: 0.0838 | top3: 0.1919 | top5: 0.2775\n",
      "\n",
      "Role ally_MIDDLE - Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.7776\n",
      "Val loss: 3.9334 | top1: 0.0808 | top3: 0.1925 | top5: 0.2756\n",
      "\n",
      "Role ally_MIDDLE - Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.7283\n",
      "Val loss: 3.9453 | top1: 0.0818 | top3: 0.1904 | top5: 0.2747\n",
      "\n",
      "Role ally_MIDDLE - Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.6732\n",
      "Val loss: 3.9753 | top1: 0.0812 | top3: 0.1862 | top5: 0.2689\n",
      "\n",
      "Role ally_MIDDLE - Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.6164\n",
      "Val loss: 3.9958 | top1: 0.0776 | top3: 0.1847 | top5: 0.2658\n",
      "\n",
      "Role ally_MIDDLE - Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5579\n",
      "Val loss: 4.0325 | top1: 0.0772 | top3: 0.1821 | top5: 0.2633\n",
      "\n",
      "Role ally_MIDDLE - Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4970\n",
      "Val loss: 4.0848 | top1: 0.0734 | top3: 0.1750 | top5: 0.2561\n",
      "\n",
      "=== Training model for role: ally_BOTTOM ===\n",
      "\n",
      "Role ally_BOTTOM - Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.2070\n",
      "Val loss: 3.1233 | top1: 0.1835 | top3: 0.3470 | top5: 0.4569\n",
      "\n",
      "Role ally_BOTTOM - Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.0856\n",
      "Val loss: 3.0773 | top1: 0.1873 | top3: 0.3593 | top5: 0.4745\n",
      "\n",
      "Role ally_BOTTOM - Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.0365\n",
      "Val loss: 3.0521 | top1: 0.1874 | top3: 0.3636 | top5: 0.4824\n",
      "\n",
      "Role ally_BOTTOM - Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.9974\n",
      "Val loss: 3.0531 | top1: 0.1875 | top3: 0.3626 | top5: 0.4806\n",
      "\n",
      "Role ally_BOTTOM - Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.9614\n",
      "Val loss: 3.0618 | top1: 0.1863 | top3: 0.3594 | top5: 0.4751\n",
      "\n",
      "Role ally_BOTTOM - Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.9219\n",
      "Val loss: 3.0805 | top1: 0.1799 | top3: 0.3557 | top5: 0.4747\n",
      "\n",
      "Role ally_BOTTOM - Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.8777\n",
      "Val loss: 3.1022 | top1: 0.1814 | top3: 0.3544 | top5: 0.4707\n",
      "\n",
      "Role ally_BOTTOM - Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.8329\n",
      "Val loss: 3.1220 | top1: 0.1747 | top3: 0.3448 | top5: 0.4643\n",
      "\n",
      "Role ally_BOTTOM - Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.7851\n",
      "Val loss: 3.1493 | top1: 0.1718 | top3: 0.3412 | top5: 0.4615\n",
      "\n",
      "Role ally_BOTTOM - Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.7350\n",
      "Val loss: 3.1917 | top1: 0.1716 | top3: 0.3411 | top5: 0.4572\n",
      "\n",
      "=== Training model for role: ally_UTILITY ===\n",
      "\n",
      "Role ally_UTILITY - Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.5976\n",
      "Val loss: 3.5162 | top1: 0.1301 | top3: 0.2819 | top5: 0.3907\n",
      "\n",
      "Role ally_UTILITY - Epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4869\n",
      "Val loss: 3.4805 | top1: 0.1333 | top3: 0.2902 | top5: 0.3967\n",
      "\n",
      "Role ally_UTILITY - Epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4434\n",
      "Val loss: 3.4721 | top1: 0.1347 | top3: 0.2899 | top5: 0.3971\n",
      "\n",
      "Role ally_UTILITY - Epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.4033\n",
      "Val loss: 3.4858 | top1: 0.1300 | top3: 0.2859 | top5: 0.3946\n",
      "\n",
      "Role ally_UTILITY - Epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.3630\n",
      "Val loss: 3.4895 | top1: 0.1295 | top3: 0.2836 | top5: 0.3919\n",
      "\n",
      "Role ally_UTILITY - Epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.3176\n",
      "Val loss: 3.5076 | top1: 0.1304 | top3: 0.2832 | top5: 0.3894\n",
      "\n",
      "Role ally_UTILITY - Epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.2693\n",
      "Val loss: 3.5200 | top1: 0.1271 | top3: 0.2776 | top5: 0.3863\n",
      "\n",
      "Role ally_UTILITY - Epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.2186\n",
      "Val loss: 3.5515 | top1: 0.1241 | top3: 0.2697 | top5: 0.3773\n",
      "\n",
      "Role ally_UTILITY - Epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.1634\n",
      "Val loss: 3.5887 | top1: 0.1253 | top3: 0.2718 | top5: 0.3777\n",
      "\n",
      "Role ally_UTILITY - Epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 3.1081\n",
      "Val loss: 3.6265 | top1: 0.1197 | top3: 0.2658 | top5: 0.3721\n",
      "\n",
      "=== Summary of best validation metrics per role ===\n",
      "ally_TOP: loss=3.8819, top1=0.0946, top3=0.2122, top5=0.2964\n",
      "ally_JUNGLE: loss=3.7454, top1=0.0821, top3=0.1993, top5=0.2904\n",
      "ally_MIDDLE: loss=3.9156, top1=0.0838, top3=0.1919, top5=0.2775\n",
      "ally_BOTTOM: loss=3.0521, top1=0.1874, top3=0.3636, top5=0.4824\n",
      "ally_UTILITY: loss=3.4721, top1=0.1347, top3=0.2899, top5=0.3971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "ally_roles = ['ally_TOP', 'ally_JUNGLE', 'ally_MIDDLE', 'ally_BOTTOM', 'ally_UTILITY']\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "val_frac = 0.2\n",
    "\n",
    "results = {}\n",
    "\n",
    "for role_slot_name in ally_roles:\n",
    "    print(f\"\\n=== Training model for role: {role_slot_name} ===\")\n",
    "\n",
    "    dataset = DraftDataset(\n",
    "        df=df,\n",
    "        champ2id=champ2id,\n",
    "        slot_cols=slot_cols,\n",
    "        role_slot_name=role_slot_name,\n",
    "        mask_id=MASK_ID,\n",
    "        pad_id=PAD_ID,\n",
    "    )\n",
    "\n",
    "    # train/val split\n",
    "    total_len = len(dataset)\n",
    "    val_len = int(total_len * val_frac)\n",
    "    train_len = total_len - val_len\n",
    "\n",
    "    train_ds, val_ds = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    val_loader   = DataLoader(val_ds, batch_size=batch_size, shuffle=False, drop_last=False)\n",
    "\n",
    "    # model\n",
    "    model = DraftSlotTransformer(\n",
    "        num_champs=vocab_size,\n",
    "        num_slots=len(slot_cols),\n",
    "        d_model=256,\n",
    "        n_heads=8,\n",
    "        n_layers=4,\n",
    "        dim_ff=512,\n",
    "        dropout=0.1,\n",
    "    ).to(device)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "\n",
    "    target_slot_idx = slot_cols.index(role_slot_name)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    best_metrics  = None\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        print(f\"\\nRole {role_slot_name} - Epoch {epoch}/{num_epochs}\")\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, target_slot_idx)\n",
    "        val_metrics = evaluate(model, val_loader, target_slot_idx)\n",
    "\n",
    "        print(f\"Train loss: {train_loss:.4f}\")\n",
    "        print(\n",
    "            \"Val loss: {loss:.4f} | top1: {top1:.4f} | top3: {top3:.4f} | top5: {top5:.4f}\".format(\n",
    "                loss=val_metrics['loss'],\n",
    "                top1=val_metrics['top1_acc'],\n",
    "                top3=val_metrics['top3_acc'],\n",
    "                top5=val_metrics['top5_acc'],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # simple best model tracking by val loss\n",
    "        if val_metrics[\"loss\"] < best_val_loss:\n",
    "            best_val_loss = val_metrics[\"loss\"]\n",
    "            best_metrics = val_metrics\n",
    "            torch.save(model.state_dict(), f\"draft_model_{role_slot_name}.pt\")\n",
    "\n",
    "    results[role_slot_name] = best_metrics\n",
    "\n",
    "print(\"\\n=== Summary of best validation metrics per role ===\")\n",
    "for role, m in results.items():\n",
    "    print(\n",
    "        f\"{role}: loss={m['loss']:.4f}, \"\n",
    "        f\"top1={m['top1_acc']:.4f}, top3={m['top3_acc']:.4f}, top5={m['top5_acc']:.4f}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
