{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75cd9a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101843, 34)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load the preprocessed bans/picks file\n",
    "df = pd.read_pickle(\"df_step2_bans_picks.pkl\")\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ab8795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>gameVersion</th>\n",
       "      <th>champion</th>\n",
       "      <th>position</th>\n",
       "      <th>slot</th>\n",
       "      <th>team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA1_5348438296</td>\n",
       "      <td>15.16.704.6097</td>\n",
       "      <td>Teemo</td>\n",
       "      <td>TOP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NA1_5348419072</td>\n",
       "      <td>15.16.704.6097</td>\n",
       "      <td>Gangplank</td>\n",
       "      <td>TOP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NA1_5345908214</td>\n",
       "      <td>15.15.701.6241</td>\n",
       "      <td>Malphite</td>\n",
       "      <td>TOP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NA1_5341292117</td>\n",
       "      <td>15.15.701.6241</td>\n",
       "      <td>Gangplank</td>\n",
       "      <td>TOP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NA1_5341241370</td>\n",
       "      <td>15.15.701.6241</td>\n",
       "      <td>Shen</td>\n",
       "      <td>TOP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matchId     gameVersion   champion position  slot  team\n",
       "0  NA1_5348438296  15.16.704.6097      Teemo      TOP     0     0\n",
       "1  NA1_5348419072  15.16.704.6097  Gangplank      TOP     0     0\n",
       "2  NA1_5345908214  15.15.701.6241   Malphite      TOP     0     0\n",
       "3  NA1_5341292117  15.15.701.6241  Gangplank      TOP     0     0\n",
       "4  NA1_5341241370  15.15.701.6241       Shen      TOP     0     0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# helper: collect all participants into a long table\n",
    "long_rows = []\n",
    "\n",
    "for i in range(10):\n",
    "    champ_col = f\"participant{i}ChampionName\"\n",
    "    pos_col   = f\"participant{i}TeamPosition\"\n",
    "    \n",
    "    tmp = df[[\"matchId\", \"gameVersion\", champ_col, pos_col]].copy()\n",
    "    tmp = tmp.rename(columns={\n",
    "        champ_col: \"champion\",\n",
    "        pos_col:   \"position\"\n",
    "    })\n",
    "    \n",
    "    tmp[\"slot\"] = i\n",
    "    tmp[\"team\"] = np.where(i < 5, 0, 1)  # 0 = blue side, 1 = red side\n",
    "    \n",
    "    long_rows.append(tmp)\n",
    "\n",
    "players_long = pd.concat(long_rows, ignore_index=True)\n",
    "\n",
    "players_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46f3afcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_picks = (\n",
    "    players_long\n",
    "    .pivot_table(\n",
    "        index=[\"matchId\", \"gameVersion\", \"team\"],\n",
    "        columns=\"position\",\n",
    "        values=\"champion\",\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    ")\n",
    "\n",
    "team_picks.columns = [f\"ally_{c}\" for c in team_picks.columns]\n",
    "team_picks = team_picks.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ac52fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>gameVersion</th>\n",
       "      <th>team</th>\n",
       "      <th>ally_BOTTOM</th>\n",
       "      <th>ally_JUNGLE</th>\n",
       "      <th>ally_MIDDLE</th>\n",
       "      <th>ally_TOP</th>\n",
       "      <th>ally_UTILITY</th>\n",
       "      <th>enemy_TOP</th>\n",
       "      <th>enemy_JUNGLE</th>\n",
       "      <th>enemy_MIDDLE</th>\n",
       "      <th>enemy_BOTTOM</th>\n",
       "      <th>enemy_UTILITY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NA1_5326075748</td>\n",
       "      <td>15.13.693.4876</td>\n",
       "      <td>0</td>\n",
       "      <td>Vayne</td>\n",
       "      <td>Kindred</td>\n",
       "      <td>Azir</td>\n",
       "      <td>Pantheon</td>\n",
       "      <td>Milio</td>\n",
       "      <td>Aatrox</td>\n",
       "      <td>Trundle</td>\n",
       "      <td>Velkoz</td>\n",
       "      <td>Smolder</td>\n",
       "      <td>Anivia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NA1_5326075748</td>\n",
       "      <td>15.13.693.4876</td>\n",
       "      <td>1</td>\n",
       "      <td>Smolder</td>\n",
       "      <td>Trundle</td>\n",
       "      <td>Velkoz</td>\n",
       "      <td>Aatrox</td>\n",
       "      <td>Anivia</td>\n",
       "      <td>Pantheon</td>\n",
       "      <td>Kindred</td>\n",
       "      <td>Azir</td>\n",
       "      <td>Vayne</td>\n",
       "      <td>Milio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NA1_5326077345</td>\n",
       "      <td>15.13.693.4876</td>\n",
       "      <td>0</td>\n",
       "      <td>Jinx</td>\n",
       "      <td>Viego</td>\n",
       "      <td>Xerath</td>\n",
       "      <td>Garen</td>\n",
       "      <td>Yuumi</td>\n",
       "      <td>Renekton</td>\n",
       "      <td>Maokai</td>\n",
       "      <td>Swain</td>\n",
       "      <td>Ezreal</td>\n",
       "      <td>Janna</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NA1_5326077345</td>\n",
       "      <td>15.13.693.4876</td>\n",
       "      <td>1</td>\n",
       "      <td>Ezreal</td>\n",
       "      <td>Maokai</td>\n",
       "      <td>Swain</td>\n",
       "      <td>Renekton</td>\n",
       "      <td>Janna</td>\n",
       "      <td>Garen</td>\n",
       "      <td>Viego</td>\n",
       "      <td>Xerath</td>\n",
       "      <td>Jinx</td>\n",
       "      <td>Yuumi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NA1_5326077813</td>\n",
       "      <td>15.13.693.4876</td>\n",
       "      <td>0</td>\n",
       "      <td>Veigar</td>\n",
       "      <td>Pantheon</td>\n",
       "      <td>AurelionSol</td>\n",
       "      <td>Chogath</td>\n",
       "      <td>MissFortune</td>\n",
       "      <td>Kennen</td>\n",
       "      <td>Hecarim</td>\n",
       "      <td>Zed</td>\n",
       "      <td>Caitlyn</td>\n",
       "      <td>Lux</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          matchId     gameVersion  team ally_BOTTOM ally_JUNGLE  ally_MIDDLE  \\\n",
       "0  NA1_5326075748  15.13.693.4876     0       Vayne     Kindred         Azir   \n",
       "1  NA1_5326075748  15.13.693.4876     1     Smolder     Trundle       Velkoz   \n",
       "2  NA1_5326077345  15.13.693.4876     0        Jinx       Viego       Xerath   \n",
       "3  NA1_5326077345  15.13.693.4876     1      Ezreal      Maokai        Swain   \n",
       "4  NA1_5326077813  15.13.693.4876     0      Veigar    Pantheon  AurelionSol   \n",
       "\n",
       "   ally_TOP ally_UTILITY enemy_TOP enemy_JUNGLE enemy_MIDDLE enemy_BOTTOM  \\\n",
       "0  Pantheon        Milio    Aatrox      Trundle       Velkoz      Smolder   \n",
       "1    Aatrox       Anivia  Pantheon      Kindred         Azir        Vayne   \n",
       "2     Garen        Yuumi  Renekton       Maokai        Swain       Ezreal   \n",
       "3  Renekton        Janna     Garen        Viego       Xerath         Jinx   \n",
       "4   Chogath  MissFortune    Kennen      Hecarim          Zed      Caitlyn   \n",
       "\n",
       "  enemy_UTILITY  \n",
       "0        Anivia  \n",
       "1         Milio  \n",
       "2         Janna  \n",
       "3         Yuumi  \n",
       "4           Lux  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roles = [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]\n",
    "ally_cols = [f\"ally_{r}\" for r in roles]\n",
    "\n",
    "# the enemy picks by flipping team\n",
    "enemy_view = team_picks[[\"matchId\", \"gameVersion\", \"team\"] + ally_cols].copy()\n",
    "\n",
    "# from each team's perspective, the enemy is the other team\n",
    "enemy_view[\"team\"] = 1 - enemy_view[\"team\"]\n",
    "\n",
    "# rename ally_* -> enemy_*\n",
    "enemy_view = enemy_view.rename(\n",
    "    columns={col: col.replace(\"ally_\", \"enemy_\") for col in ally_cols}\n",
    ")\n",
    "\n",
    "# merge back so each row has both ally_* and enemy_* picks\n",
    "team_picks_with_enemy = team_picks.merge(\n",
    "    enemy_view,\n",
    "    on=[\"matchId\", \"gameVersion\", \"team\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "team_picks_with_enemy.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63332917",
   "metadata": {},
   "outputs": [],
   "source": [
    "ban_rows = []\n",
    "\n",
    "for t in [0, 1]:\n",
    "    for i in range(5):\n",
    "        col = f\"team{t}Ban{i}ChampionName\"\n",
    "        \n",
    "        tmp = df[[\"matchId\", col]].copy()\n",
    "        tmp[\"team\"] = t\n",
    "        tmp[\"ban_index\"] = i\n",
    "        tmp[\"champion\"] = tmp[col]\n",
    "        tmp = tmp[[\"matchId\", \"team\", \"ban_index\", \"champion\"]]\n",
    "        \n",
    "        ban_rows.append(tmp)\n",
    "\n",
    "bans_long = pd.concat(ban_rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f3b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ally bans\n",
    "ally_bans = (\n",
    "    bans_long\n",
    "    .rename(columns={\"champion\": \"ally_ban\"})\n",
    "    .pivot_table(\n",
    "        index=[\"matchId\", \"team\"],\n",
    "        columns=\"ban_index\",\n",
    "        values=\"ally_ban\",\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    ")\n",
    "ally_bans.columns = [f\"ally_ban{i}\" for i in range(5)]\n",
    "ally_bans = ally_bans.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec249f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# enemy bans\n",
    "enemy_bans = (\n",
    "    bans_long\n",
    "    .assign(team=lambda x: 1 - x[\"team\"])\n",
    "    .rename(columns={\"champion\": \"enemy_ban\"})\n",
    "    .pivot_table(\n",
    "        index=[\"matchId\", \"team\"],\n",
    "        columns=\"ban_index\",\n",
    "        values=\"enemy_ban\",\n",
    "        aggfunc=\"first\"\n",
    "    )\n",
    ")\n",
    "enemy_bans.columns = [f\"enemy_ban{i}\" for i in range(5)]\n",
    "enemy_bans = enemy_bans.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2255bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wins = df[[\"matchId\", \"team0Win\", \"team1Win\"]].drop_duplicates(\"matchId\")\n",
    "\n",
    "wins_long = (\n",
    "    wins\n",
    "    .melt(id_vars=\"matchId\", value_vars=[\"team0Win\", \"team1Win\"],\n",
    "          var_name=\"t\", value_name=\"win\")\n",
    ")\n",
    "\n",
    "wins_long[\"team\"] = wins_long[\"t\"].map({\"team0Win\": 0, \"team1Win\": 1})\n",
    "wins_long = wins_long[[\"matchId\", \"team\", \"win\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19064337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['matchId', 'gameVersion', 'team', 'ally_BOTTOM', 'ally_JUNGLE', 'ally_MIDDLE', 'ally_TOP', 'ally_UTILITY', 'enemy_TOP', 'enemy_JUNGLE', 'enemy_MIDDLE', 'enemy_BOTTOM', 'enemy_UTILITY', 'ally_ban0', 'ally_ban1', 'ally_ban2', 'ally_ban3', 'ally_ban4', 'enemy_ban0', 'enemy_ban1', 'enemy_ban2', 'enemy_ban3', 'enemy_ban4', 'win']\n"
     ]
    }
   ],
   "source": [
    "team_df = (\n",
    "    team_picks_with_enemy\n",
    "    .merge(ally_bans, on=[\"matchId\", \"team\"], how=\"left\")\n",
    "    .merge(enemy_bans, on=[\"matchId\", \"team\"], how=\"left\")\n",
    "    .merge(wins_long, on=[\"matchId\", \"team\"], how=\"left\")\n",
    ")\n",
    "#print column names\n",
    "print(team_df.columns.tolist())\n",
    "#save team_df\n",
    "team_df.to_pickle(\"team_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4098ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training RF for role: TOP (target = ally_TOP) ===\n",
      "  Dropped 0 rows with too-rare TOP champs.\n",
      "  Remaining unique TOP champs: 171\n",
      "TOP: accuracy = 0.073  |  n_train = 162854, n_test = 40714\n",
      "\n",
      "=== Training RF for role: JUNGLE (target = ally_JUNGLE) ===\n",
      "  Dropped 7 rows with too-rare JUNGLE champs.\n",
      "  Remaining unique JUNGLE champs: 158\n",
      "JUNGLE: accuracy = 0.069  |  n_train = 162872, n_test = 40718\n",
      "\n",
      "=== Training RF for role: MIDDLE (target = ally_MIDDLE) ===\n",
      "  Dropped 2 rows with too-rare MIDDLE champs.\n",
      "  Remaining unique MIDDLE champs: 169\n",
      "MIDDLE: accuracy = 0.062  |  n_train = 162856, n_test = 40715\n",
      "\n",
      "=== Training RF for role: BOTTOM (target = ally_BOTTOM) ===\n",
      "  Dropped 8 rows with too-rare BOTTOM champs.\n",
      "  Remaining unique BOTTOM champs: 161\n",
      "BOTTOM: accuracy = 0.143  |  n_train = 162864, n_test = 40717\n",
      "\n",
      "=== Training RF for role: UTILITY (target = ally_UTILITY) ===\n",
      "  Dropped 2 rows with too-rare UTILITY champs.\n",
      "  Remaining unique UTILITY champs: 166\n",
      "UTILITY: accuracy = 0.118  |  n_train = 162868, n_test = 40718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "roles = [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]\n",
    "\n",
    "for role in roles:\n",
    "    print(f\"\\n=== Training RF for role: {role} (target = ally_{role}) ===\")\n",
    "    target_col = f\"ally_{role}\"\n",
    "\n",
    "    # Keep only rows where this role exists\n",
    "    role_df = team_df.dropna(subset=[target_col]).copy()\n",
    "\n",
    "    # Drop ultra-rare champs for this role\n",
    "    min_count = 2\n",
    "    vc = role_df[target_col].value_counts()\n",
    "    keep_labels = vc[vc >= min_count].index\n",
    "    n_before = len(role_df)\n",
    "    role_df = role_df[role_df[target_col].isin(keep_labels)].copy()\n",
    "    n_after = len(role_df)\n",
    "    print(f\"  Dropped {n_before - n_after} rows with too-rare {role} champs.\")\n",
    "    print(f\"  Remaining unique {role} champs: {role_df[target_col].nunique()}\")\n",
    "\n",
    "    if role_df[target_col].nunique() < 2:\n",
    "        print(\"  Not enough classes after filtering; skipping this role.\")\n",
    "        continue\n",
    "\n",
    "    # Define X, y\n",
    "    y = role_df[target_col]\n",
    "    X = role_df.drop(\n",
    "        columns=[\n",
    "            target_col,\n",
    "            \"matchId\",\n",
    "            # drop win\n",
    "            \"win\",\n",
    "            # \"team\",\n",
    "        ]\n",
    "    )\n",
    "    # Encode y\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    # Train/test split with stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y_enc,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_enc,\n",
    "    )\n",
    "\n",
    "    # Build preprocessing + RF\n",
    "    cat_cols = X.columns.tolist()\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    clf = Pipeline(\n",
    "        steps=[\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"rf\", RandomForestClassifier(\n",
    "                n_estimators=200,\n",
    "                max_depth=30,\n",
    "                min_samples_leaf=2,\n",
    "                max_features=\"sqrt\",\n",
    "                n_jobs=1,\n",
    "                random_state=42,\n",
    "            )),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Train\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    acc = clf.score(X_test, y_test)\n",
    "    print(\n",
    "        f\"{role}: accuracy = {acc:.3f}  |  \"\n",
    "        f\"n_train = {len(X_train)}, n_test = {len(X_test)}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817f4ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training RF for role: TOP (target = ally_TOP) ===\n",
      "  Dropped 0 rows with too-rare TOP champs.\n",
      "  Remaining unique TOP champs: 171\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "TOP: accuracy = 0.082\n",
      "  Best params: {'rf__n_estimators': 100, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 2, 'rf__max_features': 'sqrt', 'rf__max_depth': None}\n",
      "\n",
      "=== Training RF for role: JUNGLE (target = ally_JUNGLE) ===\n",
      "  Dropped 7 rows with too-rare JUNGLE champs.\n",
      "  Remaining unique JUNGLE champs: 158\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20235\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JUNGLE: accuracy = 0.074\n",
      "  Best params: {'rf__n_estimators': 400, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 4, 'rf__max_features': 'sqrt', 'rf__max_depth': 60}\n",
      "\n",
      "=== Training RF for role: MIDDLE (target = ally_MIDDLE) ===\n",
      "  Dropped 2 rows with too-rare MIDDLE champs.\n",
      "  Remaining unique MIDDLE champs: 169\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20235\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIDDLE: accuracy = 0.068\n",
      "  Best params: {'rf__n_estimators': 400, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 4, 'rf__max_features': 'sqrt', 'rf__max_depth': 60}\n",
      "\n",
      "=== Training RF for role: BOTTOM (target = ally_BOTTOM) ===\n",
      "  Dropped 8 rows with too-rare BOTTOM champs.\n",
      "  Remaining unique BOTTOM champs: 161\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20235\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOTTOM: accuracy = 0.177\n",
      "  Best params: {'rf__n_estimators': 100, 'rf__min_samples_split': 10, 'rf__min_samples_leaf': 2, 'rf__max_features': 'sqrt', 'rf__max_depth': None}\n",
      "\n",
      "=== Training RF for role: UTILITY (target = ally_UTILITY) ===\n",
      "  Dropped 2 rows with too-rare UTILITY champs.\n",
      "  Remaining unique UTILITY champs: 166\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20235\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\sklearn\\model_selection\\_split.py:811: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTILITY: accuracy = 0.125\n",
      "  Best params: {'rf__n_estimators': 400, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 4, 'rf__max_features': 'sqrt', 'rf__max_depth': 60}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "roles = [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]\n",
    "\n",
    "for role in roles:\n",
    "    print(f\"\\n=== Training RF for role: {role} (target = ally_{role}) ===\")\n",
    "    target_col = f\"ally_{role}\"\n",
    "\n",
    "    # Keep only rows where this role exists\n",
    "    role_df = team_df.dropna(subset=[target_col]).copy()\n",
    "\n",
    "    # Drop ultra-rare champs for this role\n",
    "    min_count = 2\n",
    "    vc = role_df[target_col].value_counts()\n",
    "    keep_labels = vc[vc >= min_count].index\n",
    "    n_before = len(role_df)\n",
    "    role_df = role_df[role_df[target_col].isin(keep_labels)].copy()\n",
    "    n_after = len(role_df)\n",
    "    print(f\"  Dropped {n_before - n_after} rows with too-rare {role} champs.\")\n",
    "    print(f\"  Remaining unique {role} champs: {role_df[target_col].nunique()}\")\n",
    "\n",
    "    if role_df[target_col].nunique() < 2:\n",
    "        print(\"  Not enough classes after filtering; skipping this role.\")\n",
    "        continue\n",
    "\n",
    "    # Define X, y\n",
    "    y = role_df[target_col]\n",
    "    X = role_df.drop(\n",
    "        columns=[\n",
    "            target_col,\n",
    "            \"matchId\",\n",
    "            # drop win\n",
    "            \"win\",\n",
    "            # \"team\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Encode target\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    # Train/test split with stratification (now safe)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y_enc,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_enc,\n",
    "    )\n",
    "\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "    # Build preprocessing\n",
    "    cat_cols = X.columns.tolist()\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Base model (Random Forest)\n",
    "    rf_base = RandomForestClassifier(random_state=42,n_jobs=-1)\n",
    "\n",
    "    pipe = Pipeline(\n",
    "        steps=[\n",
    "            (\"prep\", preprocessor),\n",
    "            (\"rf\", rf_base)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Hyperparameter space\n",
    "    param_dist = {\n",
    "        \"rf__n_estimators\": [100, 200, 400],\n",
    "        \"rf__max_depth\": [None, 20, 40, 60],\n",
    "        \"rf__min_samples_leaf\": [1, 2, 4],\n",
    "        \"rf__min_samples_split\": [2, 5, 10],\n",
    "        \"rf__max_features\": [\"sqrt\", \"log2\"],\n",
    "    }\n",
    "\n",
    "    # Randomized Search\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=12,\n",
    "        cv=3,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=1,\n",
    "        random_state=42,\n",
    "        verbose=1,\n",
    "    )\n",
    "\n",
    "    # Train using hyperparam tuning\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate\n",
    "    best_model = search.best_estimator_\n",
    "    acc = best_model.score(X_test, y_test)\n",
    "\n",
    "    print(f\"{role}: accuracy = {acc:.3f}\")\n",
    "    print(\"  Best params:\", search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4810e4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "=== Training XGBoost for role: TOP (target = ally_TOP) ===\n",
      "================================================================================\n",
      "  Initial rows for TOP: 203568\n",
      "  Downsampled to 50000 rows for tuning.\n",
      "  Dropped 4 rows with too-rare TOP champs.\n",
      "  Remaining rows: 49996\n",
      "  Remaining unique TOP champs: 163\n",
      "  Train size: 39996, Test size: 10000\n",
      "  XGBoost device: cuda\n",
      "  >> Starting RandomizedSearchCV...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[22:08:30] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 3018, 419958).\n",
      "[22:08:30] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time= 1.0min\n",
      "[22:09:31] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2987, 419958).\n",
      "[22:09:31] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  56.4s\n",
      "[22:10:27] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 3018, 419958).\n",
      "[22:10:27] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 3.5min\n",
      "[22:13:55] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2987, 419958).\n",
      "[22:13:55] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 3.6min\n",
      "[22:17:30] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 3018, 419958).\n",
      "[22:17:30] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time= 1.1min\n",
      "[22:18:38] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2987, 419958).\n",
      "[22:18:38] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time= 1.1min\n",
      "[22:19:45] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 3018, 419958).\n",
      "[22:19:45] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time= 1.3min\n",
      "[22:21:01] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2987, 419958).\n",
      "[22:21:01] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time= 1.2min\n",
      "[22:22:16] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 3018, 419958).\n",
      "[22:22:16] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  54.8s\n",
      "[22:23:11] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2987, 419958).\n",
      "[22:23:11] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  57.2s\n",
      "[22:24:08] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (39996, 3112, 839916).\n",
      "[22:24:08] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "  >> Finished search for TOP in 1010.0 seconds\n",
      "  Best CV score: 0.06373137313731372\n",
      "  Best params: {'xgb__subsample': 0.8, 'xgb__n_estimators': 200, 'xgb__min_child_weight': 1, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.1, 'xgb__colsample_bytree': 0.8}\n",
      "TOP: test accuracy = 0.077\n",
      "\n",
      "================================================================================\n",
      "=== Training XGBoost for role: JUNGLE (target = ally_JUNGLE) ===\n",
      "================================================================================\n",
      "  Initial rows for JUNGLE: 203597\n",
      "  Downsampled to 50000 rows for tuning.\n",
      "  Dropped 19 rows with too-rare JUNGLE champs.\n",
      "  Remaining rows: 49981\n",
      "  Remaining unique JUNGLE champs: 115\n",
      "  Train size: 39984, Test size: 9997\n",
      "  XGBoost device: cuda\n",
      "  >> Starting RandomizedSearchCV...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[22:25:21] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3042, 419832).\n",
      "[22:25:21] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  40.7s\n",
      "[22:26:02] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3027, 419832).\n",
      "[22:26:02] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  39.1s\n",
      "[22:26:41] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3042, 419832).\n",
      "[22:26:41] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 2.3min\n",
      "[22:29:02] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3027, 419832).\n",
      "[22:29:02] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 2.4min\n",
      "[22:31:25] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3042, 419832).\n",
      "[22:31:25] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time=  47.1s\n",
      "[22:32:13] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3027, 419832).\n",
      "[22:32:13] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time=  49.4s\n",
      "[22:33:02] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3042, 419832).\n",
      "[22:33:02] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time= 1.0min\n",
      "[22:34:05] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3027, 419832).\n",
      "[22:34:05] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  56.1s\n",
      "[22:35:01] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3042, 419832).\n",
      "[22:35:01] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  46.0s\n",
      "[22:35:47] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19992, 3027, 419832).\n",
      "[22:35:47] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  45.8s\n",
      "[22:36:33] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (39984, 3129, 839664).\n",
      "[22:36:33] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "  >> Finished search for JUNGLE in 723.4 seconds\n",
      "  Best CV score: 0.07025310124049619\n",
      "  Best params: {'xgb__subsample': 1.0, 'xgb__n_estimators': 200, 'xgb__min_child_weight': 5, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.1, 'xgb__colsample_bytree': 0.8}\n",
      "JUNGLE: test accuracy = 0.079\n",
      "\n",
      "================================================================================\n",
      "=== Training XGBoost for role: MIDDLE (target = ally_MIDDLE) ===\n",
      "================================================================================\n",
      "  Initial rows for MIDDLE: 203573\n",
      "  Downsampled to 50000 rows for tuning.\n",
      "  Dropped 6 rows with too-rare MIDDLE champs.\n",
      "  Remaining rows: 49994\n",
      "  Remaining unique MIDDLE champs: 159\n",
      "  Train size: 39995, Test size: 9999\n",
      "  XGBoost device: cuda\n",
      "  >> Starting RandomizedSearchCV...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[22:37:26] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19997, 2996, 419937).\n",
      "[22:37:26] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time= 1.1min\n",
      "[22:38:33] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2994, 419958).\n",
      "[22:38:33] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  46.6s\n",
      "[22:39:20] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19997, 2996, 419937).\n",
      "[22:39:20] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 2.2min\n",
      "[22:41:33] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2994, 419958).\n",
      "[22:41:33] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 2.2min\n",
      "[22:43:43] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19997, 2996, 419937).\n",
      "[22:43:43] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time=  41.9s\n",
      "[22:44:25] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2994, 419958).\n",
      "[22:44:25] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time=  41.8s\n",
      "[22:45:07] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19997, 2996, 419937).\n",
      "[22:45:07] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  49.3s\n",
      "[22:45:57] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2994, 419958).\n",
      "[22:45:57] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  48.1s\n",
      "[22:46:45] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19997, 2996, 419937).\n",
      "[22:46:45] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  36.7s\n",
      "[22:47:22] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19998, 2994, 419958).\n",
      "[22:47:22] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  37.0s\n",
      "[22:47:59] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (39995, 3108, 839895).\n",
      "[22:47:59] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "  >> Finished search for MIDDLE in 673.4 seconds\n",
      "  Best CV score: 0.060557542227193666\n",
      "  Best params: {'xgb__subsample': 1.0, 'xgb__n_estimators': 200, 'xgb__min_child_weight': 5, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.1, 'xgb__colsample_bytree': 0.8}\n",
      "MIDDLE: test accuracy = 0.074\n",
      "\n",
      "================================================================================\n",
      "=== Training XGBoost for role: BOTTOM (target = ally_BOTTOM) ===\n",
      "================================================================================\n",
      "  Initial rows for BOTTOM: 203589\n",
      "  Downsampled to 50000 rows for tuning.\n",
      "  Dropped 28 rows with too-rare BOTTOM champs.\n",
      "  Remaining rows: 49972\n",
      "  Remaining unique BOTTOM champs: 126\n",
      "  Train size: 39977, Test size: 9995\n",
      "  XGBoost device: cuda\n",
      "  >> Starting RandomizedSearchCV...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[22:48:40] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19988, 3050, 419748).\n",
      "[22:48:40] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  25.0s\n",
      "[22:49:06] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19989, 3030, 419769).\n",
      "[22:49:06] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  25.0s\n",
      "[22:49:31] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19988, 3050, 419748).\n",
      "[22:49:31] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 1.4min\n",
      "[22:50:53] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19989, 3030, 419769).\n",
      "[22:50:53] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 1.4min\n",
      "[22:52:17] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19988, 3050, 419748).\n",
      "[22:52:17] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time=  32.7s\n",
      "[22:52:50] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19989, 3030, 419769).\n",
      "[22:52:50] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time=  30.7s\n",
      "[22:53:21] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19988, 3050, 419748).\n",
      "[22:53:21] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  30.9s\n",
      "[22:53:52] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19989, 3030, 419769).\n",
      "[22:53:52] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  30.5s\n",
      "[22:54:22] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19988, 3050, 419748).\n",
      "[22:54:22] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  25.9s\n",
      "[22:54:48] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19989, 3030, 419769).\n",
      "[22:54:48] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  25.1s\n",
      "[22:55:14] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (39977, 3133, 839517).\n",
      "[22:55:14] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "  >> Finished search for BOTTOM in 421.3 seconds\n",
      "  Best CV score: 0.18105415878473002\n",
      "  Best params: {'xgb__subsample': 0.8, 'xgb__n_estimators': 200, 'xgb__min_child_weight': 5, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.05, 'xgb__colsample_bytree': 1.0}\n",
      "BOTTOM: test accuracy = 0.185\n",
      "\n",
      "================================================================================\n",
      "=== Training XGBoost for role: UTILITY (target = ally_UTILITY) ===\n",
      "================================================================================\n",
      "  Initial rows for UTILITY: 203588\n",
      "  Downsampled to 50000 rows for tuning.\n",
      "  Dropped 16 rows with too-rare UTILITY champs.\n",
      "  Remaining rows: 49984\n",
      "  Remaining unique UTILITY champs: 146\n",
      "  Train size: 39987, Test size: 9997\n",
      "  XGBoost device: cuda\n",
      "  >> Starting RandomizedSearchCV...\n",
      "Fitting 2 folds for each of 5 candidates, totalling 10 fits\n",
      "[22:55:43] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19993, 3024, 419853).\n",
      "[22:55:43] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  30.6s\n",
      "[22:56:13] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19994, 3007, 419874).\n",
      "[22:56:13] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  30.7s\n",
      "[22:56:44] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19993, 3024, 419853).\n",
      "[22:56:44] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 1.8min\n",
      "[22:58:31] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19994, 3007, 419874).\n",
      "[22:58:31] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.05, xgb__max_depth=5, xgb__min_child_weight=1, xgb__n_estimators=400, xgb__subsample=0.8; total time= 1.8min\n",
      "[23:00:18] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19993, 3024, 419853).\n",
      "[23:00:18] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time=  36.0s\n",
      "[23:00:54] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19994, 3007, 419874).\n",
      "[23:00:54] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=1, xgb__n_estimators=200, xgb__subsample=0.8; total time=  36.4s\n",
      "[23:01:31] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19993, 3024, 419853).\n",
      "[23:01:31] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  39.5s\n",
      "[23:02:10] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19994, 3007, 419874).\n",
      "[23:02:10] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=1.0, xgb__learning_rate=0.1, xgb__max_depth=5, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=0.8; total time=  40.2s\n",
      "[23:02:51] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19993, 3024, 419853).\n",
      "[23:02:51] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  32.9s\n",
      "[23:03:24] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (19994, 3007, 419874).\n",
      "[23:03:24] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "[CV] END xgb__colsample_bytree=0.8, xgb__learning_rate=0.1, xgb__max_depth=3, xgb__min_child_weight=5, xgb__n_estimators=200, xgb__subsample=1.0; total time=  33.0s\n",
      "[23:03:57] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\iterative_dmatrix.cc:56: Finished constructing the `IterativeDMatrix`: (39987, 3120, 839727).\n",
      "[23:03:57] INFO: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\data\\ellpack_page.cu:174: Ellpack is sparse.\n",
      "  >> Finished search for UTILITY in 529.2 seconds\n",
      "  Best CV score: 0.12266485427546936\n",
      "  Best params: {'xgb__subsample': 1.0, 'xgb__n_estimators': 200, 'xgb__min_child_weight': 5, 'xgb__max_depth': 3, 'xgb__learning_rate': 0.1, 'xgb__colsample_bytree': 0.8}\n",
      "UTILITY: test accuracy = 0.126\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "roles = [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]\n",
    "\n",
    "for role in roles:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"=== Training XGBoost for role: {role} (target = ally_{role}) ===\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    target_col = f\"ally_{role}\"\n",
    "\n",
    "    # keep only rows where this role exists\n",
    "    role_df = team_df.dropna(subset=[target_col]).copy()\n",
    "    print(f\"  Initial rows for {role}: {len(role_df)}\")\n",
    "\n",
    "    # downsample for speed\n",
    "    max_rows = 50_000\n",
    "    if len(role_df) > max_rows:\n",
    "        role_df = role_df.sample(n=max_rows, random_state=42)\n",
    "        print(f\"  Downsampled to {len(role_df)} rows for tuning.\")\n",
    "\n",
    "    # drop ultra-rare champs so stratify doesn't explode\n",
    "    min_count = 2\n",
    "    vc = role_df[target_col].value_counts()\n",
    "    keep_labels = vc[vc >= min_count].index\n",
    "    n_before = len(role_df)\n",
    "    role_df = role_df[role_df[target_col].isin(keep_labels)].copy()\n",
    "    n_after = len(role_df)\n",
    "    print(f\"  Dropped {n_before - n_after} rows with too-rare {role} champs.\")\n",
    "    print(f\"  Remaining rows: {n_after}\")\n",
    "    print(f\"  Remaining unique {role} champs: {role_df[target_col].nunique()}\")\n",
    "\n",
    "    if role_df[target_col].nunique() < 2:\n",
    "        print(\"  Not enough classes after filtering; skipping this role.\")\n",
    "        continue\n",
    "\n",
    "    # define X, y\n",
    "    y = role_df[target_col]\n",
    "    X = role_df.drop(columns=[target_col, \"matchId\", \"win\"])\n",
    "\n",
    "    # encode target\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    # train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y_enc,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_enc\n",
    "    )\n",
    "    print(f\"  Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "    # one-hot encode all categorical features\n",
    "    cat_cols = X.columns.tolist()\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)]\n",
    "    )\n",
    "\n",
    "    # base XGB model (GPU\n",
    "    xgb = XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",\n",
    "        verbosity=2,\n",
    "        random_state=42,\n",
    "    )\n",
    "\n",
    "    print(\"  XGBoost device:\", xgb.get_params()[\"device\"])\n",
    "\n",
    "    # PIPELINE\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"xgb\", xgb)])\n",
    "\n",
    "    param_dist = {\n",
    "        \"xgb__n_estimators\":      [200, 400],\n",
    "        \"xgb__max_depth\":         [3, 5],\n",
    "        \"xgb__learning_rate\":     [0.1, 0.05],\n",
    "        \"xgb__subsample\":         [0.8, 1.0],\n",
    "        \"xgb__colsample_bytree\":  [0.8, 1.0],\n",
    "        \"xgb__min_child_weight\":  [1, 5],\n",
    "    }\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=5,\n",
    "        cv=2,\n",
    "        verbose=2,\n",
    "        n_jobs=1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    print(\"  >> Starting RandomizedSearchCV...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Fit random search (GPU\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  >> Finished search for {role} in {elapsed:.1f} seconds\")\n",
    "\n",
    "    print(\"  Best CV score:\", search.best_score_)\n",
    "    print(\"  Best params:\", search.best_params_)\n",
    "\n",
    "    # Evaluate on held-out test set\n",
    "    test_acc = search.score(X_test, y_test)\n",
    "    print(f\"{role}: test accuracy = {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac3ca0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "=== FINAL XGBoost train for role: TOP (target = ally_TOP) ===\n",
      "================================================================================\n",
      "  Rows for TOP: 203568\n",
      "  Dropped 0 rows with too-rare TOP champs.\n",
      "  Remaining rows: 203568\n",
      "  Remaining unique TOP champs: 171\n",
      "  Train size: 162854, Test size: 40714\n",
      "  XGBoost device: cuda\n",
      "  XGBoost params: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "  >> Fitting final model...\n",
      "  >> Finished training for TOP in 62.1 seconds\n",
      "TOP: FINAL test accuracy = 0.092\n",
      "\n",
      "================================================================================\n",
      "=== FINAL XGBoost train for role: JUNGLE (target = ally_JUNGLE) ===\n",
      "================================================================================\n",
      "  Rows for JUNGLE: 203597\n",
      "  Dropped 7 rows with too-rare JUNGLE champs.\n",
      "  Remaining rows: 203590\n",
      "  Remaining unique JUNGLE champs: 158\n",
      "  Train size: 162872, Test size: 40718\n",
      "  XGBoost device: cuda\n",
      "  XGBoost params: {'subsample': 1.0, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "  >> Fitting final model...\n",
      "  >> Finished training for JUNGLE in 47.9 seconds\n",
      "JUNGLE: FINAL test accuracy = 0.083\n",
      "\n",
      "================================================================================\n",
      "=== FINAL XGBoost train for role: MIDDLE (target = ally_MIDDLE) ===\n",
      "================================================================================\n",
      "  Rows for MIDDLE: 203573\n",
      "  Dropped 2 rows with too-rare MIDDLE champs.\n",
      "  Remaining rows: 203571\n",
      "  Remaining unique MIDDLE champs: 169\n",
      "  Train size: 162856, Test size: 40715\n",
      "  XGBoost device: cuda\n",
      "  XGBoost params: {'subsample': 1.0, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "  >> Fitting final model...\n",
      "  >> Finished training for MIDDLE in 56.1 seconds\n",
      "MIDDLE: FINAL test accuracy = 0.082\n",
      "\n",
      "================================================================================\n",
      "=== FINAL XGBoost train for role: BOTTOM (target = ally_BOTTOM) ===\n",
      "================================================================================\n",
      "  Rows for BOTTOM: 203589\n",
      "  Dropped 8 rows with too-rare BOTTOM champs.\n",
      "  Remaining rows: 203581\n",
      "  Remaining unique BOTTOM champs: 161\n",
      "  Train size: 162864, Test size: 40717\n",
      "  XGBoost device: cuda\n",
      "  XGBoost params: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.05, 'colsample_bytree': 1.0}\n",
      "  >> Fitting final model...\n",
      "  >> Finished training for BOTTOM in 51.0 seconds\n",
      "BOTTOM: FINAL test accuracy = 0.187\n",
      "\n",
      "================================================================================\n",
      "=== FINAL XGBoost train for role: UTILITY (target = ally_UTILITY) ===\n",
      "================================================================================\n",
      "  Rows for UTILITY: 203588\n",
      "  Dropped 2 rows with too-rare UTILITY champs.\n",
      "  Remaining rows: 203586\n",
      "  Remaining unique UTILITY champs: 166\n",
      "  Train size: 162868, Test size: 40718\n",
      "  XGBoost device: cuda\n",
      "  XGBoost params: {'subsample': 1.0, 'n_estimators': 200, 'min_child_weight': 5, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "  >> Fitting final model...\n",
      "  >> Finished training for UTILITY in 53.3 seconds\n",
      "UTILITY: FINAL test accuracy = 0.131\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "#copied from logs\n",
    "best_params_per_role = {\n",
    "    \"TOP\": {\n",
    "        \"subsample\": 0.8,\n",
    "        \"n_estimators\": 200,\n",
    "        \"min_child_weight\": 1,\n",
    "        \"max_depth\": 3,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "    },\n",
    "    \"JUNGLE\": {\n",
    "        \"subsample\": 1.0,\n",
    "        \"n_estimators\": 200,\n",
    "        \"min_child_weight\": 5,\n",
    "        \"max_depth\": 3,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "    },\n",
    "    \"MIDDLE\": {\n",
    "        \"subsample\": 1.0,\n",
    "        \"n_estimators\": 200,\n",
    "        \"min_child_weight\": 5,\n",
    "        \"max_depth\": 3,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "    },\n",
    "    \"BOTTOM\": {\n",
    "        \"subsample\": 0.8,\n",
    "        \"n_estimators\": 200,\n",
    "        \"min_child_weight\": 5,\n",
    "        \"max_depth\": 3,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"colsample_bytree\": 1.0,\n",
    "    },\n",
    "    \"UTILITY\": {\n",
    "        \"subsample\": 1.0,\n",
    "        \"n_estimators\": 200,\n",
    "        \"min_child_weight\": 5,\n",
    "        \"max_depth\": 3,\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"colsample_bytree\": 0.8,\n",
    "    },\n",
    "}\n",
    "\n",
    "roles = [\"TOP\", \"JUNGLE\", \"MIDDLE\", \"BOTTOM\", \"UTILITY\"]\n",
    "\n",
    "for role in roles:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"=== FINAL XGBoost train for role: {role} (target = ally_{role}) ===\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    target_col = f\"ally_{role}\"\n",
    "\n",
    "    # keep only rows where this role exists\n",
    "    role_df = team_df.dropna(subset=[target_col]).copy()\n",
    "    print(f\"  Rows for {role}: {len(role_df)}\")\n",
    "\n",
    "    # drop ultra-rare champs\n",
    "    min_count = 2\n",
    "    vc = role_df[target_col].value_counts()\n",
    "    keep_labels = vc[vc >= min_count].index\n",
    "    n_before = len(role_df)\n",
    "    role_df = role_df[role_df[target_col].isin(keep_labels)].copy()\n",
    "    n_after = len(role_df)\n",
    "    print(f\"  Dropped {n_before - n_after} rows with too-rare {role} champs.\")\n",
    "    print(f\"  Remaining rows: {n_after}\")\n",
    "    print(f\"  Remaining unique {role} champs: {role_df[target_col].nunique()}\")\n",
    "\n",
    "    if role_df[target_col].nunique() < 2:\n",
    "        print(\"  Not enough classes after filtering; skipping this role.\")\n",
    "        continue\n",
    "\n",
    "    # define X, y\n",
    "    y = role_df[target_col]\n",
    "    X = role_df.drop(columns=[target_col, \"matchId\", \"win\"])\n",
    "\n",
    "    # encode target\n",
    "    le = LabelEncoder()\n",
    "    y_enc = le.fit_transform(y)\n",
    "\n",
    "    # train/test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y_enc,\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "        stratify=y_enc,\n",
    "    )\n",
    "    print(f\"  Train size: {len(X_train)}, Test size: {len(X_test)}\")\n",
    "\n",
    "    # one-hot encode all categorical features\n",
    "    cat_cols = X.columns.tolist()\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[(\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols)]\n",
    "    )\n",
    "\n",
    "    # XGB model with role-specific best params\n",
    "    params = best_params_per_role[role]\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        objective=\"multi:softprob\",\n",
    "        eval_metric=\"mlogloss\",\n",
    "        tree_method=\"hist\",\n",
    "        device=\"cuda\",         # GPU\n",
    "        verbosity=1,\n",
    "        random_state=42,\n",
    "        **params,\n",
    "    )\n",
    "    print(\"  XGBoost device:\", xgb.get_params()[\"device\"])\n",
    "    print(\"  XGBoost params:\", params)\n",
    "\n",
    "    # PIPELINE\n",
    "    pipe = Pipeline(steps=[(\"prep\", preprocessor), (\"xgb\", xgb)])\n",
    "\n",
    "    # Fit once\n",
    "    print(\"  >> Fitting final model...\")\n",
    "    start_time = time.time()\n",
    "    pipe.fit(X_train, y_train)\n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"  >> Finished training for {role} in {elapsed:.1f} seconds\")\n",
    "\n",
    "    # Evaluate on held-out test set\n",
    "    test_acc = pipe.score(X_test, y_test)\n",
    "    print(f\"{role}: FINAL test accuracy = {test_acc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
